{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.368853Z",
     "start_time": "2018-03-30T16:14:59.786820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anders1991/miniconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Keras\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anders1991/deepbreath\n"
     ]
    }
   ],
   "source": [
    "% cd /Users/anders1991/deepbreath/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.417385Z",
     "start_time": "2018-03-30T16:15:01.379913Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"test\"\n",
    "classification = False\n",
    "timesteps = 1\n",
    "batch_size = 5\n",
    "learn_rate = 1e-4\n",
    "max_epochs = 50\n",
    "downsample = 2\n",
    "droprate = 0.5\n",
    "overfit = True\n",
    "\n",
    "if classification:\n",
    "    loss = \"categorical_crossentropy\"\n",
    "else:\n",
    "    loss = \"mean_absolute_error\"\n",
    "\n",
    "if learn_rate > 0:\n",
    "    optimizer = Adam(lr = learn_rate)\n",
    "    opt = \"Adam\"\n",
    "else:\n",
    "    optimizer = Nadam()\n",
    "    opt = \"Nadam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.424349Z",
     "start_time": "2018-03-30T16:15:01.419726Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/partition.pkl\", 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "    \n",
    "if overfit:\n",
    "    partition[\"train\"] = partition[\"train\"][:20]\n",
    "    partition[\"valid\"] = partition[\"valid\"][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.440168Z",
     "start_time": "2018-03-30T16:15:01.426883Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"./data/ERU_Scores_Ids_5-Scans_Validity-0_VisuallyScored.csv\")\n",
    "labels = target.set_index(\"StId\").to_dict()[\"ERU.M2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.450842Z",
     "start_time": "2018-03-30T16:15:01.442720Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rescale labels\n",
    "if classification:\n",
    "    # combine 0+1 as 0 = no emph in scan, 1 = no emph in region\n",
    "    label_converter = {0: 0, 1: 0, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
    "else:\n",
    "    # Rescale labels;\n",
    "    label_converter = {0: 0.0, 1: 0.0, 2: 0.03, 3: 0.155, 4: 0.38, 5: 0.63, 6: 0.88}\n",
    "labels = {key: label_converter[val] for key, val in labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate class weights\n",
    "\n",
    "To handle imbalanced classes during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.477249Z",
     "start_time": "2018-03-30T16:15:01.453306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.498705Z",
     "start_time": "2018-03-30T16:15:01.479793Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights only based on training data\n",
    "train_labels = [label for key, label in labels.items() if key in partition[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.657421Z",
     "start_time": "2018-03-30T16:15:01.501826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(train_labels), \n",
    "                                                  y=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.664537Z",
     "start_time": "2018-03-30T16:15:01.659792Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scripts.data_gen import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.677005Z",
     "start_time": "2018-03-30T16:15:01.667824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainGen = DataGenerator(\"train\", classification=classification, batch_size=batch_size,\n",
    "                         timesteps=timesteps, channels=1, dim_x=142, dim_y=322, dim_z=262, shuffle=True)\n",
    "validGen = DataGenerator(\"valid\", classification=classification, batch_size=batch_size,\n",
    "                         timesteps=timesteps, channels=1, dim_x=142, dim_y=322, dim_z=262, shuffle=True)\n",
    "\n",
    "trainGen = trainGen.generate(labels, partition[\"train\"])\n",
    "validGen = validGen.generate(labels, partition[\"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:01.684163Z",
     "start_time": "2018-03-30T16:15:01.679940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scripts.unet import tdist_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:02.241310Z",
     "start_time": "2018-03-30T16:15:01.687440Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tdist_unet(classification=classification, timesteps=timesteps, downsample=downsample, droprate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:02.278222Z",
     "start_time": "2018-03-30T16:15:02.243547Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "              loss=loss, \n",
    "              metrics=['accuracy', 'mae', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:02.286339Z",
     "start_time": "2018-03-30T16:15:02.280870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory = \"./output/\"+name+\"/\"\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# with open(\"./output/\"+name+\"/config.txt\", \"w\") as txt:\n",
    "#     txt.write(\"name = {0}\\n\".format(name))\n",
    "#     txt.write(\"timesteps = {0}\\n\".format(timesteps))\n",
    "#     txt.write(\"batch_size = {0}\\n\".format(batch_size))\n",
    "#     txt.write(\"learn_rate = {0}\\n\".format(learn_rate))\n",
    "#     txt.write(\"max_epochs= {0}\\n\".format(max_epochs))\n",
    "#     txt.write(\"downsample = {0}\\n\".format(downsample))\n",
    "#     txt.write(\"droprate = {0}\\n\".format(droprate))\n",
    "#     txt.write(\"mode = {0}\\n\".format(mode))\n",
    "#     txt.write(\"loss = {0}\\n\".format(loss))\n",
    "#     txt.write(\"opt = {0}\\n\".format(opt))\n",
    "\n",
    "# callbacks_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights each epoch if best val acc so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:02.293498Z",
     "start_time": "2018-03-30T16:15:02.289825Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modeldir = directory + \"epoch_{epoch:02d}-valacc_{val_acc:.2f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(modeldir, monitor='val_acc', save_weights_only=False, save_best_only=True, mode='max', verbose=1)\n",
    "# callbacks_list.append(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add TensorBoard callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:02.299108Z",
     "start_time": "2018-03-30T16:15:02.295956Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from TBCallbacks import TrainValTensorBoard\n",
    "\n",
    "# tensorboard= TrainValTensorBoard(log_dir=\"./output/\"+name+\"/logs\", histogram_freq=0, write_graph=True, write_images=True) # custom TB writer object\n",
    "# callbacks_list.append(tensorboard) # add tensorboard logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T16:15:02.305011Z",
     "start_time": "2018-03-30T16:15:02.301823Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hist = model.fit_generator(generator = trainGen,\n",
    "#                            steps_per_epoch = len(partition[\"train\"])//batch_size,\n",
    "#                            validation_data = validGen,\n",
    "#                            validation_steps = len(partition[\"valid\"])//batch_size,\n",
    "#                            class_weight = class_weights,\n",
    "#                            epochs = max_epochs,\n",
    "#                            callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
